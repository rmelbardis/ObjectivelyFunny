{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea9e65bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/cbeams/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk; nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3ce05ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfdd0c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Adam Devine' 'Adam Hess' 'Adam Hills' 'Adam Sandler' 'Adel Karam'\n",
      " 'Aisling Bea' 'Al Madrigal' 'Al Murray' 'Al Porter' 'Alan Carr'\n",
      " 'Alex Edelman' 'Ali Wong' 'Alistair McGowan' 'Amanda Seales'\n",
      " 'Amy Schumer' 'Andi Osho' 'Andrew Lawrence' 'Andrew Maxwell'\n",
      " 'Andy Parsons' 'Andy Woodhull' 'Angela Barnes' 'Anjelah Johnson'\n",
      " 'Anthony Jeselnik' 'Ari Shaffir' 'Arj Barker' 'Arsenio Hall'\n",
      " 'Aziz Ansari' 'Bert Kreischer' 'Big Jay Oakerson' 'Bill Burr'\n",
      " 'Bill Hicks' 'Bill Maher' 'Billy Connolly' 'Bo Burnham' 'Bob Monkhouse'\n",
      " 'Brad Williams' 'Brent Morin' 'Brian Regan' 'Bridget Everett'\n",
      " 'Cedric The Entertainer' 'Celia Pacquola' 'Chelsea Peretti'\n",
      " 'Chris Addison' \"Chris D'Elia\" 'Chris Gethard' 'Chris McCausland'\n",
      " 'Chris Moyles' 'Chris Ramsey' 'Chris Rock' 'Chris Tucker'\n",
      " 'Christina Pazsitzky' 'Colin Quinn' 'Craig Ferguson' 'Cristela Alonzo'\n",
      " 'D.l. Hughley' 'Dan Soder' 'Dana Carvey' 'Dane Baptiste' 'Daniel Tosh'\n",
      " 'Danny Bhoy' 'Dara Ó Briain' 'Darren Harriott' 'Dave Allen' 'Dave Attell'\n",
      " 'Dave Chappelle' 'David Cross' \"David O'Doherty\" 'Dawn French'\n",
      " 'Demetri Martin' 'Deray Davis' 'Desiree Burch' 'Dick Gregory' 'Doc Brown'\n",
      " 'Donald Glover' 'Doug Stanhope' 'Drew Michael' 'Dylan Moran' 'Ed Byrne'\n",
      " 'Eddie Griffin' 'Eddie Izzard' 'Eddie Murphy' 'Ellen Degeneres'\n",
      " 'Ellie Taylor' 'Emily Heller' 'Enissa Amani' 'Eric Andre' 'Erik Griffin'\n",
      " 'Fahim Anwar' 'Felicity Ward' 'Francesca Martinez' 'Frankie Boyle'\n",
      " 'Fred Armisen' 'Gabriel Iglesias' 'Gary Delaney' 'Geoff Norcott'\n",
      " 'George Carlin' 'George Lopez' 'Gina Yashere' 'Greg Davies' 'Guz Khan'\n",
      " 'Hal Cruttenden' 'Hannah Gadsby' 'Hannibal Buress' 'Hasan Minhaj'\n",
      " 'Henning Wehn' 'Henry Rollins' 'Holly Walsh' 'Iliza Shlesinger'\n",
      " 'Ivo Graham' 'Jack Carroll' 'Jack Dee' 'Jack Whitehall' 'Jamali Maddix'\n",
      " 'James Acaster' 'Jason Byrne' 'Jason Manford' 'Jeff Foxworthy'\n",
      " 'Jen Brister' 'Jen Kirkman' 'Jerry Seinfeld' 'Jim Gaffigan'\n",
      " 'Jim Jefferies' 'Jim Norton' 'Jimeoin' 'Jimmy Carr' 'Jimmy O. Yang'\n",
      " 'Jo Koy' 'Joe List' 'Joe Lycett' 'Joe Mande' 'Joe Rogan' 'John Bishop'\n",
      " 'John Leguizamo' 'John Mulaney' 'Jon Richardson' 'Josh Widdicombe'\n",
      " 'Judah Friedlander' 'Julian Clary' 'Justin Moorhouse' 'Katherine Ryan'\n",
      " 'Kathleen Madigan' 'Katt Williams' 'Kavin Jay' 'Ken Jeong'\n",
      " 'Kenny Sebastian' 'Kerry Godliman' 'Kevin Bridges' 'Kevin Hart'\n",
      " 'Kevin James' 'Kevin Smith' 'Larry Dean' 'Larry The Cable Guy' 'Lee Mack'\n",
      " 'Lee Nelson' 'Lenny Bruce' 'Lenny Henry' 'Lewis Black' 'Lisa Lampanelli'\n",
      " 'Louis C. K.' 'Lucy Porter' 'Luisa Omielan' 'Mae Martin' 'Marc Maron'\n",
      " 'Marcus Brigstocke' 'Maria Bamford' 'Mark Normand' 'Mark Watson'\n",
      " 'Marlon Wayans' 'Maz Jobrani' 'Michael Che' 'Michael McIntyre'\n",
      " 'Michael Mcintyre' 'Michelle Wolf' 'Micky Flanagan' 'Mike Birbiglia'\n",
      " 'Mike Epps' 'Mike Wilmot' 'Miles Jupp' 'Milton Jones' 'Miranda Hart'\n",
      " 'Mitch Hedberg' 'Mo Amer' 'Nate Bargatze' 'Nathan Caton' 'Neal Brennan'\n",
      " 'Nick Helm' 'Nick Offerman' 'Nikki Glaser' 'Nish Kumar' 'Noel Fielding'\n",
      " 'Norm Macdonald' 'Omid Djalili' 'Pablo Francisco' 'Patrice O’Neal'\n",
      " 'Patrick Kielty' 'Patton Oswalt' 'Paul Chowdhry' 'Paul Mooney'\n",
      " 'Pete Davidson' 'Pete Holmes' 'Peter Kay' 'Phil Wang' 'Phill Jupitus'\n",
      " 'Ralphie May' 'Ramy Youssef' 'Ray Romano' 'Reggie Watts'\n",
      " 'Reginald D Hunter' 'Rhod Gilbert' 'Rich Hall' 'Richard Pryor'\n",
      " 'Ricky Gervais' 'Rob Beckett' 'Rob Brydon' 'Rob Schneider'\n",
      " 'Robin Williams' 'Roisin Conaty' 'Romesh Ranganathan' 'Ron White'\n",
      " 'Ronny Chieng' 'Rory Scovel' 'Roy Wood Jr.' 'Russell Brand'\n",
      " 'Russell Howard' 'Russell Kane' 'Russell Peters' 'Ryan Hamilton'\n",
      " 'Sam Jay' 'Sam Morril' 'Sam Simmons' 'Sara Pascoe' 'Sarah Cooper'\n",
      " 'Sarah Millican' 'Sarah Silverman' 'Sean Lock' 'Seann Walsh'\n",
      " 'Sebastian Maniscalco' 'Seth Meyers' 'Shappi Khorsandi' 'Simon Amstell'\n",
      " 'Simon Evans' 'Spencer Jones' 'Stephen K. Amos' 'Steve Hughes'\n",
      " 'Stewart Francis' 'Stewart Lee' 'T.j. Miller' 'Terry Alderton'\n",
      " 'Tez Ilyas' 'Tiffany Haddish' 'Tig Notaro' 'Tim Vine' 'Todd Barry'\n",
      " 'Todd Glass' 'Tom Allen' 'Tom Papa' 'Tom Segura' 'Tom Stade'\n",
      " 'Tommy Tiernan' 'Trevor Noah' 'Urzila Carlson' 'Victoria Wood' 'Vir Das'\n",
      " 'Volker Pispers' 'W. Kamau Bell' 'Wanda Sykes' 'Whitney Cummings'\n",
      " 'Zoe Lyons']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_transcript</th>\n",
       "      <th>artist</th>\n",
       "      <th>show_name</th>\n",
       "      <th>year</th>\n",
       "      <th>source</th>\n",
       "      <th>artist_birthday</th>\n",
       "      <th>artist_gender</th>\n",
       "      <th>age_then</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[rock music playing]\\n\\n[indistinct chatter]\\n...</td>\n",
       "      <td>Adam Devine</td>\n",
       "      <td>Best Time Of Our Lives</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Scraps from the Loft</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>2</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>strong language. CHEERING Yes, yes, yes! How...</td>\n",
       "      <td>Adam Hess</td>\n",
       "      <td>Live from the BBC</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ladies and gentlemen, please welcome your hos...</td>\n",
       "      <td>Adam Hills</td>\n",
       "      <td>Live at the Apollo Series 9 Episode 4</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>some strong language and adult humour Ladies...</td>\n",
       "      <td>Adam Hills</td>\n",
       "      <td>Live at the Apollo Series 12 Episode 4</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>? CHEERING Hello, Apollo. I am going to start ...</td>\n",
       "      <td>Adam Hills</td>\n",
       "      <td>Live at the Apollo Series 5 Episode 5</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     full_transcript       artist  \\\n",
       "0  [rock music playing]\\n\\n[indistinct chatter]\\n...  Adam Devine   \n",
       "1    strong language. CHEERING Yes, yes, yes! How...    Adam Hess   \n",
       "2   Ladies and gentlemen, please welcome your hos...   Adam Hills   \n",
       "3    some strong language and adult humour Ladies...   Adam Hills   \n",
       "4  ? CHEERING Hello, Apollo. I am going to start ...   Adam Hills   \n",
       "\n",
       "                                show_name    year                source  \\\n",
       "0                  Best Time Of Our Lives  2019.0  Scraps from the Loft   \n",
       "1                       Live from the BBC  2016.0                   BBC   \n",
       "2   Live at the Apollo Series 9 Episode 4  2013.0                   BBC   \n",
       "3  Live at the Apollo Series 12 Episode 4  2016.0                   BBC   \n",
       "4   Live at the Apollo Series 5 Episode 5  2009.0                   BBC   \n",
       "\n",
       "   artist_birthday  artist_gender  age_then  \n",
       "0           1983.0              2      36.0  \n",
       "1           1990.0              2      26.0  \n",
       "2           1970.0              2      43.0  \n",
       "3           1970.0              2      46.0  \n",
       "4           1970.0              2      39.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Dataset\n",
    "df = pd.read_json('../raw_data/all_data_df.json')\n",
    "print(df.artist.unique())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d63a0837",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Specific functions to our data - Scraps from the Loft and BBC\n",
    "\n",
    "# remove notes (Bo Burnham Only)\n",
    "def clean_bo(text):\n",
    "    txt = text\n",
    "    for note in '♫♪':\n",
    "        txt = txt.replace(note, '')\n",
    "    return txt\n",
    "\n",
    "def remove_music(text):\n",
    "    text = re.sub('♪.*?♪', '', text) # remove ♪ stuff that looks like this ♪\n",
    "    text = re.sub('♫.*?♫', '', text) # remove ♫ stuff that looks like this ♫\n",
    "    return text\n",
    "\n",
    "def remove_bracketed(text):\n",
    "    text = re.sub('\\[.*?\\]', '', text) # remove [stuff that looks like this]\n",
    "    text = re.sub('\\(.*?\\)', '', text) # remove (stuff that looks like this)\n",
    "    return text\n",
    "\n",
    "def remove_speaker_tags(text):\n",
    "    text = re.sub('\\s[\\w-]+( \\w+)?:\\s', ' ', text) # remove Word: or Word word: with a newline or space before\n",
    "    return text\n",
    "\n",
    "def remove_info(text):\n",
    "    text = re.sub('subtitle(s)? by .*', '', str(text)) # remove subtile(s) by xxxx\n",
    "    text = re.sub('(a)? netflix (original )?(comedy )?(special ?)?', '', text) # remove A Netflix Original Comedy Special\n",
    "    text = re.sub('(this )?(programme )?(contains )?(very |some )?strong language( |\\.)', '', text) # remove strong language\n",
    "    text = re.sub('adult humou?r( |\\.?)?', '', text) # remove adult humour\n",
    "    text = re.sub('(original )?air date', '', text) # remove air date\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eeb7f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general functions for text pre-processing\n",
    "def remove_punc(text, chars):\n",
    "    txt = text\n",
    "    for punc in chars:\n",
    "        txt = txt.replace(punc, '')\n",
    "    return txt\n",
    "\n",
    "def remove_num(text):\n",
    "    return ''.join(char for char in text if not char.isdigit())\n",
    "\n",
    "def remove_stopw(text, word_list):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    return ' '.join(w for w in word_tokens if not w in word_list)\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "def lemmatize(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return ' '.join(lemmatizer.lemmatize(word) for word in text.split(' ') if len(lemmatizer.lemmatize(word))>2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c39ba613",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer_dict = {'get': 'got',\n",
    "                   'go': 'gon',\n",
    "                   'say': 'said',\n",
    "                   'fuck': ['fucking', 'f*ck', 'f_ck', 'f**k', 'f***'],\n",
    "                   'bitch': ['b*tch', 'b_tch', 'b****', 'b**ch', 'b***h'],\n",
    "                   'shit':['sh*t', 'sh_t', 's**t', 's***'],\n",
    "                   'go': 'went',\n",
    "                   'find': 'finding'}\n",
    "\n",
    "def manual_lemmatizer(text):\n",
    "    for k, v in lemmatizer_dict.items():\n",
    "        text.replace(v, k)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50d7eca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c755b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_transcript</th>\n",
       "      <th>artist</th>\n",
       "      <th>show_name</th>\n",
       "      <th>year</th>\n",
       "      <th>source</th>\n",
       "      <th>artist_birthday</th>\n",
       "      <th>artist_gender</th>\n",
       "      <th>age_then</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[rock music playing]\\n\\n[indistinct chatter]\\n...</td>\n",
       "      <td>Adam Devine</td>\n",
       "      <td>Best Time Of Our Lives</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Scraps from the Loft</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>2</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>strong language. CHEERING Yes, yes, yes! How...</td>\n",
       "      <td>Adam Hess</td>\n",
       "      <td>Live from the BBC</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ladies and gentlemen, please welcome your hos...</td>\n",
       "      <td>Adam Hills</td>\n",
       "      <td>Live at the Apollo Series 9 Episode 4</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>some strong language and adult humour Ladies...</td>\n",
       "      <td>Adam Hills</td>\n",
       "      <td>Live at the Apollo Series 12 Episode 4</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>? CHEERING Hello, Apollo. I am going to start ...</td>\n",
       "      <td>Adam Hills</td>\n",
       "      <td>Live at the Apollo Series 5 Episode 5</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>Ladies and gentlemen… !\\n\\nYes. Yes. Thank you...</td>\n",
       "      <td>Wanda Sykes</td>\n",
       "      <td>Not Normal</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Scraps from the Loft</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>1</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>(techno music playing) ♪ ♪ ♪ Play it, say it, ...</td>\n",
       "      <td>Whitney Cummings</td>\n",
       "      <td>I’m Your Girlfriend</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Scraps from the Loft</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>1</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>Ladies and gentlemen, from the Barclay Theatre...</td>\n",
       "      <td>Whitney Cummings</td>\n",
       "      <td>I Love You</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Scraps from the Loft</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>Ladies and gentlemen… !\\n\\nThis is awesome. I ...</td>\n",
       "      <td>Whitney Cummings</td>\n",
       "      <td>Can I Touch It?</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Scraps from the Loft</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>, ladies and gentlemen! CHEERING AND APPLAUSE ...</td>\n",
       "      <td>Zoe Lyons</td>\n",
       "      <td>Live at the Apollo Series 11 Episode 2</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>1</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>555 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       full_transcript            artist  \\\n",
       "0    [rock music playing]\\n\\n[indistinct chatter]\\n...       Adam Devine   \n",
       "1      strong language. CHEERING Yes, yes, yes! How...         Adam Hess   \n",
       "2     Ladies and gentlemen, please welcome your hos...        Adam Hills   \n",
       "3      some strong language and adult humour Ladies...        Adam Hills   \n",
       "4    ? CHEERING Hello, Apollo. I am going to start ...        Adam Hills   \n",
       "..                                                 ...               ...   \n",
       "550  Ladies and gentlemen… !\\n\\nYes. Yes. Thank you...       Wanda Sykes   \n",
       "551  (techno music playing) ♪ ♪ ♪ Play it, say it, ...  Whitney Cummings   \n",
       "552  Ladies and gentlemen, from the Barclay Theatre...  Whitney Cummings   \n",
       "553  Ladies and gentlemen… !\\n\\nThis is awesome. I ...  Whitney Cummings   \n",
       "554  , ladies and gentlemen! CHEERING AND APPLAUSE ...         Zoe Lyons   \n",
       "\n",
       "                                  show_name    year                source  \\\n",
       "0                    Best Time Of Our Lives  2019.0  Scraps from the Loft   \n",
       "1                         Live from the BBC  2016.0                   BBC   \n",
       "2     Live at the Apollo Series 9 Episode 4  2013.0                   BBC   \n",
       "3    Live at the Apollo Series 12 Episode 4  2016.0                   BBC   \n",
       "4     Live at the Apollo Series 5 Episode 5  2009.0                   BBC   \n",
       "..                                      ...     ...                   ...   \n",
       "550                              Not Normal  2019.0  Scraps from the Loft   \n",
       "551                     I’m Your Girlfriend  2016.0  Scraps from the Loft   \n",
       "552                              I Love You  2014.0  Scraps from the Loft   \n",
       "553                         Can I Touch It?  2019.0  Scraps from the Loft   \n",
       "554  Live at the Apollo Series 11 Episode 2  2015.0                   BBC   \n",
       "\n",
       "     artist_birthday  artist_gender  age_then  \n",
       "0             1983.0              2      36.0  \n",
       "1             1990.0              2      26.0  \n",
       "2             1970.0              2      43.0  \n",
       "3             1970.0              2      46.0  \n",
       "4             1970.0              2      39.0  \n",
       "..               ...            ...       ...  \n",
       "550           1964.0              1      55.0  \n",
       "551           1982.0              1      34.0  \n",
       "552           1982.0              1      32.0  \n",
       "553           1982.0              1      37.0  \n",
       "554           1971.0              1      44.0  \n",
       "\n",
       "[555 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd6d527d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['full_transcript_clean'] = clean_df['full_transcript'].apply(remove_bracketed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6d43b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wx/fdznh_y51_1gnn8tvkcxhsyh0000gn/T/ipykernel_36647/3470318112.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['full_transcript_clean'][clean_df['artist']=='Bo Burnham'] = clean_df['full_transcript_clean'][clean_df['artist']=='Bo Burnham'].apply(clean_bo)\n"
     ]
    }
   ],
   "source": [
    "### clean Bo before removing music\n",
    "clean_df['full_transcript_clean'][clean_df['artist']=='Bo Burnham'] = clean_df['full_transcript_clean'][clean_df['artist']=='Bo Burnham'].apply(clean_bo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8eae3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['full_transcript_clean'] = clean_df['full_transcript_clean'].apply(remove_music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "faada3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase all the words\n",
    "clean_df['full_transcript_clean'] = clean_df['full_transcript_clean'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a83e935e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove speaker tags and info regexes\n",
    "clean_df['full_transcript_clean'] = clean_df['full_transcript_clean'].apply(remove_info)\n",
    "clean_df['full_transcript_clean'] = clean_df['full_transcript_clean'].apply(remove_speaker_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0a1c414",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['full_transcript_clean'] = clean_df['full_transcript_clean'].apply(remove_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a13358d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### additional words to remove from the scripts\n",
    "words_to_remove = ['thank', 'cheering', 'recorded', 'applause', 'laughter', 'laughing', 'murmuring', 'chatter',\n",
    "                       'aired', 'filmed', 'ladies', 'gentlemen', 'welcome', 'stage', 'transcript', 'netflix',\n",
    "                  'apollo', 'like', 'goodnight', 'mutter', 'noo', 'nuh', 'oof', 'maan', 'cause', 'okay', \n",
    "                   'hey', 'also', 'someone', 'somebody', 'everybody', 'also', 'part' , 'sometimes', 'maybe', \n",
    "                   'three', 'second', 'everything', 'minute', 'name', 'kind', 'point', 'yeah', 'hello', 'one', \n",
    "                   'two', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'whine', 'hnn', 'malla', 'letta', \n",
    "                   'namoo', 'getta', 'nama', 'mana', 'chk','manoo', 'hadda', 'ama', 'carlin',\n",
    "                  'go', 'know', 'host', 'goodnight', 'get', 'gon', 'think', 'say', 'right', 'look',\n",
    "                  'thing', 'make', 'know', 'want', 'going', 'would', 'could', 'gentlemen', 'let', 'please',\n",
    "                   'hbo', 'special' 'yes', 'take', 'say', 'got', 'come', 'see', 'really', 'tell',\n",
    "                   'well', 'give', 'said']\n",
    "                    \n",
    "                    # 'know'? 'go'? 'fuck'?\n",
    "    \n",
    "                    # haven't left 'i'm' etc. as those should be cleaned up\n",
    "                    # by a mixture of stopwords, punctuation removeal, lemmatizing and minimum length\n",
    "\n",
    "clean_df['full_transcript_clean'] = clean_df['full_transcript_clean'].apply(remove_stopw, args=(words_to_remove,))\n",
    "clean_df['full_transcript_clean'] = clean_df['full_transcript_clean'].apply(remove_stopw, args=(stopwords.words('english'),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a546a8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "punc_added = string.punctuation + '“”‘’…♪♫¶'\n",
    "\n",
    "clean_df['full_transcript_clean'] = clean_df['full_transcript_clean'].apply(remove_punc, args=(punc_added,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05a40d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['full_transcript_clean'] = clean_df['full_transcript_clean'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7302917a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "replace() argument 1 must be str, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wx/fdznh_y51_1gnn8tvkcxhsyh0000gn/T/ipykernel_36647/2093815240.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclean_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'full_transcript_clean'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'full_transcript_clean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmanual_lemmatizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/objectively_funny/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4431\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4432\u001b[0m         \"\"\"\n\u001b[0;32m-> 4433\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4435\u001b[0m     def _reduce(\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/objectively_funny/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1080\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/objectively_funny/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1135\u001b[0m                 \u001b[0;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m                 \u001b[0;31m# \"Callable[[Any], Any]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1137\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1138\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/objectively_funny/lib/python3.8/site-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/var/folders/wx/fdznh_y51_1gnn8tvkcxhsyh0000gn/T/ipykernel_36647/3160034212.py\u001b[0m in \u001b[0;36mmanual_lemmatizer\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmanual_lemmatizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlemmatizer_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: replace() argument 1 must be str, not list"
     ]
    }
   ],
   "source": [
    "clean_df['full_transcript_clean'] = clean_df['full_transcript_clean'].apply(manual_lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ac0231",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e679907f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_json('../raw_data/all_data_df_stripped.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69856f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['full_transcript_clean'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
