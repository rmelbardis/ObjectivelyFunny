{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46fd3d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e284423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.ldamodel import LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b1ebf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b98f1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from google.cloud import storage\n",
    "\n",
    "# from ObjectivelyFunny import cloud_paths\n",
    "from ObjectivelyFunny.pipeline import set_pipeline\n",
    "from ObjectivelyFunny.data import get_data, sent_to_words\n",
    "from ObjectivelyFunny import word_selections\n",
    "\n",
    "from gensim.models import phrases, Phrases\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "class LDATrainer():\n",
    "\n",
    "    def __init__(self, update_every=5, model_name='model'):\n",
    "        self.model_name = model_name\n",
    "        self.update_every = update_every\n",
    "\n",
    "    def make_words(self, X):\n",
    "        self.transcript_list = X['full_transcript'].values.tolist()\n",
    "        self.words = list(sent_to_words(self.transcript_list))\n",
    "        return self\n",
    "\n",
    "    def make_grams(self):\n",
    "        self.bigram = Phrases(self.words, min_count=3, threshold=5)\n",
    "        self.trigram = Phrases(self.bigram[self.words], threshold=3)\n",
    "        self.bigram_mod = phrases.Phraser(self.bigram)\n",
    "        self.trigram_mod = phrases.Phraser(self.trigram)\n",
    "        self.bigrams = [self.bigram_mod[word] for word in self.words]\n",
    "        self.trigrams = [self.trigram_mod[self.bigram_mod[word]] for word in self.words]\n",
    "        return self\n",
    "\n",
    "    def make_dictionary(self):\n",
    "        self.id2word = corpora.Dictionary(self.bigrams)\n",
    "        self.corpus = [self.id2word.doc2bow(bigram) for bigram in self.bigrams]\n",
    "        return self\n",
    "\n",
    "    def run(self):\n",
    "        self.model = LdaModel(corpus=self.corpus,\n",
    "                        id2word=self.id2word,\n",
    "                        update_every=self.update_every,\n",
    "                        num_topics=31,\n",
    "                        random_state=100,\n",
    "                        chunksize=15,\n",
    "                        passes=10,\n",
    "                        alpha=0.4,\n",
    "                        eta=0.5,\n",
    "                        per_word_topics=True)\n",
    "        return self\n",
    "\n",
    "    def save_model(self):\n",
    "        '''\n",
    "        saves model\n",
    "        '''\n",
    "        # client = storage.Client()\n",
    "        # bucket = client.get_bucket(cloud_paths.BUCKET_NAME)\n",
    "        # blob = bucket.blob(f'{cloud_paths.STORAGE_LOCATION}{self.model_name}')\n",
    "\n",
    "        # Save model to disk.\n",
    "        self.model.save(f'LDA_models/{self.model_name}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # gender topic search\n",
    "    name_dict = {'1': 'LDA_pre_1990',\n",
    "                 '2': 'LDA_90s',\n",
    "                 '3': 'LDA_00s',\n",
    "                 '4': 'LDA_10s',\n",
    "                 '5': 'LDA_20s'}\n",
    "\n",
    "    year_list = [list(range(1960, 1990)),\n",
    "                 list(range(1990, 2000)),\n",
    "                 list(range(2000, 2010)),\n",
    "                 list(range(2010, 2020)),\n",
    "                 list(range(2020, 2023))]\n",
    "\n",
    "    for i, decade in enumerate(year_list):\n",
    "        print(f'Starting run {i+1}:')\n",
    "        df = get_data(year=decade)\n",
    "        print('Data acquired')\n",
    "        clean_steps = ['music', 'brackets', 'lowercase', 'regex', 'numbers', 'uncensor', 'remove', 'punctuation',\n",
    "        'lemmatizer', 'manual_lemmatize', 'remove2']\n",
    "        clean_df = set_pipeline(clean_steps,\n",
    "                            dropword_list = word_selections.standard_dropword_list + word_selections.decade_dropword_list\n",
    "                            ).fit_transform(df)\n",
    "        print('Dataframe cleaned')\n",
    "\n",
    "        model = LDATrainer(update_every=5, model_name=name_dict[str(i)])\n",
    "        model.make_words(clean_df).make_grams().make_dictionary()\n",
    "        print('Gram dictionary made')\n",
    "        model.run()\n",
    "        print('Model finished running')\n",
    "        model.save_model()\n",
    "        print('model_saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89972f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232f93fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ObjectivelyFunny.LDA_trainer import LDATrainer\n",
    "from ObjectivelyFunny.pipeline import set_pipeline\n",
    "from ObjectivelyFunny.data import get_data, sent_to_words\n",
    "from ObjectivelyFunny import word_selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4603a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b750062",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LdaModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wx/fdznh_y51_1gnn8tvkcxhsyh0000gn/T/ipykernel_6764/291271381.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLdaModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'LdaModel' is not defined"
     ]
    }
   ],
   "source": [
    "lda = LdaModel.load('../model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81aafae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241b9ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = Dictionary.load('../model.id2word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d35baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_data(gender=[1])\n",
    "print('Data acquired')\n",
    "clean_steps = ['music', 'brackets', 'lowercase', 'regex', 'numbers', 'uncensor', 'remove', 'punctuation',\n",
    "'lemmatizer', 'manual_lemmatize', 'remove2']\n",
    "clean_df = set_pipeline(clean_steps,\n",
    "                dropword_list = word_selections.standard_dropword_list + word_selections.decade_dropword_list\n",
    "                ).fit_transform(df)\n",
    "print('Dataframe cleaned')\n",
    "\n",
    "model = LDATrainer()\n",
    "model.make_words(clean_df).make_grams().make_dictionary()\n",
    "print('Gram dictionary made')\n",
    "model.run()\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dfa926",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0a0e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda, model.corpus, model.id2word, mds='mmds')\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1aab27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "for t in range(lda.num_topics):\n",
    "    plt.figure()\n",
    "    plt.imshow(WordCloud().fit_words(dict(lda.show_topic(t, 200))))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Topic #\" + str(t))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d78427",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
