{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7be37490",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "import string\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2a606d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2e2abc",
   "metadata": {},
   "source": [
    "# Preprocessing of Text for Analysis Purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681b5afa",
   "metadata": {},
   "source": [
    "## Import the new dataframe\n",
    "(that has artist names removed from transcripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8523c0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('../raw_data/df_all_clean .json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0a32f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "555"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f95465",
   "metadata": {},
   "source": [
    "## Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d62d672",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Specific functions to our data - Scraps from the Loft and BBC\n",
    "\n",
    "# remove notes (Bo Burnham Only)\n",
    "def clean_bo(text):\n",
    "    txt = text\n",
    "    for note in '♫♪':\n",
    "        txt = txt.replace(note, '')\n",
    "    return txt\n",
    "\n",
    "def remove_music(text):\n",
    "    text = re.sub('♪.*?♪', '', text) # remove ♪ stuff that looks like this ♪\n",
    "    text = re.sub('♫.*?♫', '', text) # remove ♫ stuff that looks like this ♫\n",
    "    return text\n",
    "\n",
    "def remove_bracketed(text):\n",
    "    text = re.sub('\\[.*?\\]', '', text) # remove [stuff that looks like this]\n",
    "    text = re.sub('\\(.*?\\)', '', text) # remove (stuff that looks like this)\n",
    "    return text\n",
    "\n",
    "def remove_speaker_tags(text):\n",
    "    text = re.sub('\\s[\\w-]+( \\w+)?:\\s', ' ', text) # remove Word: or Word word: with a newline or space before\n",
    "    return text\n",
    "\n",
    "def remove_info(text):\n",
    "    text = re.sub('subtitle(s)? by .*', '', str(text)) # remove subtile(s) by xxxx\n",
    "    text = re.sub('(a)? netflix (original )?(comedy )?(special ?)?', '', text) # remove A Netflix Original Comedy Special\n",
    "    text = re.sub('(this )?(programme )?(contains )?(very |some )?strong language( |\\.)', '', text) # remove strong language\n",
    "    text = re.sub('adult humou?r( |\\.?)?', '', text) # remove adult humour\n",
    "    text = re.sub('(original )?air date', '', text) # remove air date\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0117c700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general functions for text pre-processing\n",
    "def remove_punc(text, chars):\n",
    "    txt = text\n",
    "    for punc in chars:\n",
    "        txt = txt.replace(punc, '')\n",
    "    return txt\n",
    "\n",
    "def remove_num(text):\n",
    "    return ''.join(char for char in text if not char.isdigit())\n",
    "\n",
    "def remove_stopw(text, word_list):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    return ' '.join(w for w in word_tokens if not w in word_list)\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "def lemmatize(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return ' '.join(lemmatizer.lemmatize(word) for word in text.split(' ') if len(lemmatizer.lemmatize(word))>2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2635604",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer_dict = {'got': 'get',\n",
    "                  'gon': 'go',\n",
    "                  'said': 'say',\n",
    "                  'fucking': 'fuck',\n",
    "                  'went': 'go',\n",
    "                  'finding': 'find'}\n",
    "\n",
    "def manual_lemmatizer(text):\n",
    "    for k, v in lemmatizer_dict.items():\n",
    "        text.replace(k, v)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f3e000",
   "metadata": {},
   "source": [
    "## Modifying & applying removal lists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98b250e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a81d93",
   "metadata": {},
   "source": [
    "### Remove everything in Brackets, Music notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c90eedb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['full_transcript_clean'] = clean_df['full_transcript'].apply(remove_bracketed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "898f0d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/jf61hd8n2cj411r4h4mdpyf00000gn/T/ipykernel_82029/3470318112.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['full_transcript_clean'][clean_df['artist']=='Bo Burnham'] = clean_df['full_transcript_clean'][clean_df['artist']=='Bo Burnham'].apply(clean_bo)\n"
     ]
    }
   ],
   "source": [
    "### clean Bo before removing music\n",
    "clean_df['full_transcript_clean'][clean_df['artist']=='Bo Burnham'] = clean_df['full_transcript_clean'][clean_df['artist']=='Bo Burnham'].apply(clean_bo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58168060",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['full_transcript_clean'] = clean_df['full_transcript_clean'].apply(remove_music)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0467722c",
   "metadata": {},
   "source": [
    "### Lowercase, remove useless regex matches\n",
    "Including specific scraps/BBC format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd8c7d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase all the words\n",
    "clean_df['full_transcript_clean'] = clean_df['full_transcript_clean'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfbccfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove speaker tags and info regexes\n",
    "clean_df['full_transcript_clean'] = clean_df['full_transcript_clean'].apply(remove_info)\n",
    "clean_df['full_transcript_clean'] = clean_df['full_transcript_clean'].apply(remove_speaker_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01677862",
   "metadata": {},
   "source": [
    "### Remove numbers and stopwords + common comedy words, remove punctuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c8db133",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['full_transcript_clean'] = clean_df['full_transcript_clean'].apply(remove_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39740276",
   "metadata": {},
   "outputs": [],
   "source": [
    "### additional words to remove from the scripts\n",
    "words_to_remove = ['thank', 'cheering', 'recorded', 'applause', 'laughter', 'laughing', 'murmuring', 'chatter',\n",
    "                       'aired', 'filmed', 'ladies', 'gentlemen', 'welcome', 'stage', 'transcript', 'netflix']\n",
    "                    \n",
    "                    # 'know'? 'go'? 'fuck'?\n",
    "    \n",
    "                    # haven't left 'i'm' etc. as those should be cleaned up\n",
    "                    # by a mixture of stopwords, punctuation removeal, lemmatizing and minimum length\n",
    "\n",
    "stopwords_plus = words_to_remove + stopwords.words('english')\n",
    "\n",
    "clean_df['full_transcript_clean'] = clean_df['full_transcript_clean'].apply(remove_stopw, args=(stopwords_plus,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47ba0596",
   "metadata": {},
   "outputs": [],
   "source": [
    "punc_added = string.punctuation + '“”‘’…♪♫¶'\n",
    "\n",
    "clean_df['full_transcript_clean'] = clean_df['full_transcript_clean'].apply(remove_punc, args=(punc_added,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008b37a1",
   "metadata": {},
   "source": [
    "### Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2b73acf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean_df['full_transcript_clean'] = clean_df['full_transcript_clean'].apply(lemmatize).apply(manual_lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54e716ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_transcript</th>\n",
       "      <th>artist</th>\n",
       "      <th>show_name</th>\n",
       "      <th>year</th>\n",
       "      <th>source</th>\n",
       "      <th>full_transcript_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[rock music playing]\\n\\n[indistinct chatter]\\n...</td>\n",
       "      <td>Adam Devine</td>\n",
       "      <td>Best Time Of Our Lives</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Scraps from the Loft</td>\n",
       "      <td>hey man let hey everybody right yeah guy much ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>strong language. CHEERING Yes, yes, yes! How...</td>\n",
       "      <td>Adam Hess</td>\n",
       "      <td>Live from the BBC</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>yes yes yes well hello lovely name going apolo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ladies and gentlemen, please welcome your hos...</td>\n",
       "      <td>Adam Hills</td>\n",
       "      <td>Live at the Apollo Series 9 Episode 4</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>please host tonight hello london hello london ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>some strong language and adult humour Ladies...</td>\n",
       "      <td>Adam Hills</td>\n",
       "      <td>Live at the Apollo Series 12 Episode 4</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>please host tonight hello apollo know hair los...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>? CHEERING Hello, Apollo. I am going to start ...</td>\n",
       "      <td>Adam Hills</td>\n",
       "      <td>Live at the Apollo Series 5 Episode 5</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>BBC</td>\n",
       "      <td>hello apollo going start saying something prob...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     full_transcript       artist  \\\n",
       "0  [rock music playing]\\n\\n[indistinct chatter]\\n...  Adam Devine   \n",
       "1    strong language. CHEERING Yes, yes, yes! How...    Adam Hess   \n",
       "2   Ladies and gentlemen, please welcome your hos...   Adam Hills   \n",
       "3    some strong language and adult humour Ladies...   Adam Hills   \n",
       "4  ? CHEERING Hello, Apollo. I am going to start ...   Adam Hills   \n",
       "\n",
       "                                show_name    year                source  \\\n",
       "0                  Best Time Of Our Lives  2019.0  Scraps from the Loft   \n",
       "1                       Live from the BBC  2016.0                   BBC   \n",
       "2   Live at the Apollo Series 9 Episode 4  2013.0                   BBC   \n",
       "3  Live at the Apollo Series 12 Episode 4  2016.0                   BBC   \n",
       "4   Live at the Apollo Series 5 Episode 5  2009.0                   BBC   \n",
       "\n",
       "                               full_transcript_clean  \n",
       "0  hey man let hey everybody right yeah guy much ...  \n",
       "1  yes yes yes well hello lovely name going apolo...  \n",
       "2  please host tonight hello london hello london ...  \n",
       "3  please host tonight hello apollo know hair los...  \n",
       "4  hello apollo going start saying something prob...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "858f60d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "southern california ready good time tonight get ex\n"
     ]
    }
   ],
   "source": [
    "print(clean_df['full_transcript_clean'].iloc[69][:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8e2abf",
   "metadata": {},
   "source": [
    "## LDA model to see topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10ea437f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "[('goodnight', 0.3348600161358118), ('maan', 0.3339742967188974), ('noo', 0.3339445631377952), ('nuh', 0.3339287259404283), ('mutter', 0.33389748648941336), ('hnn', 0.33389077167026066), ('whine', 0.33389031947489706), ('acquisition', 0.33387004397340786), ('oof', 0.3338618936778319), ('apollo', 0.33385300312805033)]\n",
      "Topic 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beebo/.pyenv/versions/3.8.12/envs/objectively_funny/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('like', 135.38685103556776), ('know', 82.46404860960116), ('get', 54.19933252480247), ('got', 50.2767673107016), ('right', 44.08902408619648), ('one', 41.73659395670489), ('people', 40.89759584006824), ('said', 33.769553889540234), ('going', 31.47938325148181), ('think', 31.299183447645326)]\n",
      "Topic 2:\n",
      "[('goodnight', 0.3348600150078791), ('maan', 0.33397415099035976), ('noo', 0.3339444329219937), ('nuh', 0.33392860055907114), ('mutter', 0.3338973762371726), ('hnn', 0.3338907843179997), ('whine', 0.3338902001859849), ('acquisition', 0.3338700286378614), ('oof', 0.33386192343516435), ('apollo', 0.3338530042412585)]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer().fit(clean_df['full_transcript_clean'])\n",
    "data_vectorized = vectorizer.transform(clean_df['full_transcript_clean'])\n",
    "lda_model = LatentDirichletAllocation(n_components=3).fit(data_vectorized)\n",
    "\n",
    "def print_topics(model, vectorizer):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names()[i], topic[i])\n",
    "                        for i in topic.argsort()[:-10 - 1:-1]])\n",
    "        \n",
    "\n",
    "print_topics(lda_model, vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149a01a4",
   "metadata": {},
   "source": [
    "## Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ae1d594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_bow(df):\n",
    "    keys = df.sum().index\n",
    "    values = df.sum().values\n",
    "    bow_dict = dict(zip(keys, values))\n",
    "    return bow_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8802a00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beebo/.pyenv/versions/3.8.12/envs/objectively_funny/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "603"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first bow\n",
    "\n",
    "t = clean_df['full_transcript_clean'].astype(str)\n",
    "\n",
    "vectorizer = CountVectorizer(min_df = 0.3, max_df = 0.8, ngram_range=(1,1))\n",
    "X = vectorizer.fit_transform(t)\n",
    "bow_df1 = pd.DataFrame(X.toarray(),columns = vectorizer.get_feature_names())\n",
    "len(bow_df1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "282aba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_1 = dict_bow(bow_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edb9e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_df = clean_df['full_transcript_clean'].apply(tokenize).astype(str)\n",
    "token_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95afd28a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.Series([y for x in token_df.values.flatten() for y in x.split()]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4868d8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequent_words = ['like']\n",
    "# clean_df['full_transcript_clean'] = clean_df['full_transcript_clean'].apply(remove_stopw, args=(frequent_words,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79560189",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_transcripts = ' '.join(clean_df['full_transcript_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dd46d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(full_transcripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605892ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to plot word cloud\n",
    "def plot_cloud(wordcloud):\n",
    "    # Set figure size\n",
    "    plt.figure(figsize=(30, 20))\n",
    "    # Display image\n",
    "    plt.imshow(wordcloud) \n",
    "    # No axis details\n",
    "    plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411c03af",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cloud = WordCloud(width=3000, height = 2000,\n",
    "                       random_state=1, colormap='Pastel1',\n",
    "                       collocations=False, stopwords = STOPWORDS).generate(full_transcripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8b9c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cloud(word_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c409c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cloud2 = WordCloud(width=3000, height = 2000,\n",
    "                       random_state=1, colormap='Pastel1',\n",
    "                       collocations=False, stopwords = STOPWORDS).generate_from_frequencies(bow_dict)\n",
    "plot_cloud(word_cloud2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26310b19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
